{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text from Germany party programs\n",
    "\n",
    "How often do certain keywords come up in different party programmes? The goal here is a dataframe summarizing the different party programms.\n",
    "\n",
    "As a first step, we are importing the required packages reading in the data, cleaning it from stopwords, and plotting some relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tika in c:\\programdata\\anaconda3\\lib\\site-packages (1.24)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from tika) (2.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tika) (50.3.1.post20201107)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tika) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tika) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tika) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tika) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "!pip install tika\n",
    "from tika import parser \n",
    "import glob\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing names of considered party programmes\n",
    "\n",
    "Printing all files that are located in the `party_programmes`-folder inside of the Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['party_programmes\\\\eyjg.pdf', 'party_programmes\\\\FDP_BTW2021_Wahlprogramm_1.pdf', 'party_programmes\\\\gruene.txt', 'party_programmes\\\\programm_der_partei_die_linke_erfurt2011_druckfassung2020.pdf', 'party_programmes\\\\Wahlprogramm-DIE-GRUENEN-Bundestagswahl-2021_barrierefrei.pdf']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob('party_programmes/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the party programmes \n",
    "\n",
    "Here, all programs are stored in a new object. In the second step, the `parser.from.file`-function is used in order to create separate objects for each party's program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\carlo\\\\Dokumente\\\\GitHub\\\\Data-Structures-and-Algorithms-Final-Project\\\\party_programmes\\\\SPD-Zukunftsprogramm.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d60d1fae588d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mspd_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'party_programmes/SPD-Zukunftsprogramm.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcdu_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'party_programmes/eyjg.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mafd_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'party_programmes/20210611_AfD_Programm_2021.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tika\\parser.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(filename, serverEndpoint, service, xmlContent, headers, config_path, requestOptions)\u001b[0m\n\u001b[0;32m     38\u001b[0m     '''\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxmlContent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserverEndpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequestOptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequestOptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         output = parse1(service, filename, serverEndpoint, services={'meta': '/meta', 'text': '/tika', 'all': '/rmeta/xml'},\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tika\\tika.py\u001b[0m in \u001b[0;36mparse1\u001b[1;34m(option, urlOrPath, serverEndpoint, verbose, tikaServerJar, responseMimeType, services, rawResponse, headers, config_path, requestOptions)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mservice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'/tika'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresponseMimeType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'text/plain'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Accept'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresponseMimeType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Content-Disposition'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmake_content_disposition_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0municode_string\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0murlOrPath\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_is_file_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlOrPath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         status, response = callServer('put', serverEndpoint, service, f,\n\u001b[0;32m    337\u001b[0m                                       \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtikaServerJar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\carlo\\\\Dokumente\\\\GitHub\\\\Data-Structures-and-Algorithms-Final-Project\\\\party_programmes\\\\SPD-Zukunftsprogramm.pdf'"
     ]
    }
   ],
   "source": [
    "files = glob.glob('party_programmes/*')\n",
    "\n",
    "\n",
    "spd_raw = parser.from_file('party_programmes/SPD-Zukunftsprogramm.pdf')\n",
    "cdu_raw = parser.from_file('party_programmes/eyjg.pdf')\n",
    "afd_raw = parser.from_file('party_programmes/20210611_AfD_Programm_2021.pdf')\n",
    "fdp_raw = parser.from_file('party_programmes/FDP_BTW2021_Wahlprogramm_1.pdf')\n",
    "linke_raw = parser.from_file('party_programmes/DIE_LINKE_Wahlprogramm_zur_Bundestagswahl_2021.pdf')\n",
    "gruene_raw = parser.from_file('party_programmes/Wahlprogramm-DIE-GRUENEN-Bundestagswahl-2021_barrierefrei.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First transformations\n",
    "\n",
    "In the next chunk, the programs are cleaned for further analysis: Linebreaks are removed, the `word_tokenize`-function is used to splitting up the tect into words and German stopwords are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove linebreaks\n",
    "nonnewline = spd_raw['content'].strip()\n",
    "\n",
    "#separate the text into individual words\n",
    "text_tokens = word_tokenize(nonnewline)\n",
    "\n",
    "#delete all stopwords\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('german')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out how many words we could inspect\n",
    "counted_words = Counter(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each word we can access the number of words we got\n",
    "counted_words[\"Klimawandels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open(r\"party_programmes/gruene.txt\",\"a\")\n",
    "file1.writelines(gruene_raw['content'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acf825a93f1d67e9b21f3d7be3de1b7301682f1e83d4489e56181e84878ca65e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
