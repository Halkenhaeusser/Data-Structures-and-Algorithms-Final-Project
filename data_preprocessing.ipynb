{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "As a first step, all packages for the data prepocessing/data acquisition are imported. The tweepy library (https://docs.tweepy.org/en/stable/) can be used to access the Twitter API for storing the relevant tweets and further information. Pandas is imported for first minor data transformations and reading in the politician's twitter handles. The os library is used to check the path of the configuration file which contains the import tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweepy version: 4.3.0\n",
      "Pandas version: 1.1.3\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Tweepy version: \" + tweepy.__version__)\n",
    "print(\"Pandas version: \" + pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the relevant consumer keys and access tokens\n",
    "\n",
    "The respective keys and tokens were retrieved from the personal twitter developer account and stored in a separate file (config.py). The next chunk extracts the keys and tokens from the config file, which itself is not pushed to the GitHub repository. The if-else statement prints a confirmation in case that a config file exists on the local machine of the user, and an alternative statement if it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokens from config.py file\n",
    "if os.path.isfile(\"config.py\"):\n",
    "    print(\"config.py exists\\nAPI keys and tokens are imported\")\n",
    "    from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "else:\n",
    "    print(\"config.py does not exist\\nPlease add config.py to proceed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up API\n",
    "\n",
    "In the next chunk, the previously stored consumer keys are passed to the OAuthHandler instance, using the tweepy library. Subsequently, also the access token and secret need to be set up (which we also have stored in strings in the previous chunk). Finally, a new API variable is created. The `wait_on_rate_limit`-argument is set to true (this is useful since there are certain rate limits set by Twitter which should not be exceeded). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup consumer API key\n",
    "auth = tweepy.OAuthHandler(\n",
    "    consumer_key,\n",
    "    consumer_secret\n",
    ")\n",
    "\n",
    "# setup access token\n",
    "auth.set_access_token(\n",
    "    access_token,\n",
    "    access_token_secret\n",
    ")\n",
    "\n",
    "# create API variable\n",
    "api = tweepy.API(\n",
    "    auth, \n",
    "    wait_on_rate_limit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionality test of the API credentials\n",
    "\n",
    "In this code chunk, the `verify_credentials`-function checks whether the credentials we read in earlier are valid. If so, a confirmation statement is printed. If the function runs into an error, an error message is printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "# check if API credentials work\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Twitter API\n",
    "\n",
    "After setting up the credentials, we check whether we can extract the most recent tweet in Lukas' timeline. For this task, we are using tweepy's `user_timeline`-function and storing its output in a new object. Inside of the function, we have to specify several arguments: The respective twitter handle/username, the number of tweets we want to extract, whether we want to include retweets (which we do not), and that we want to extract the whole tweet (and not a truncated version). Subsequently, the function `timeline_to_df` is created, which takes a tweepy object has an input and converts it into a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    @p_c_bauer @MichaelImre Nice project! Seems to be a very rare coincidence, I worked basically on the same project last year while using the same name ðŸ˜„\\nhttps://t.co/QQtOQ...\n",
      "Name: full_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# test if user_timeline method works with own twitter account\n",
    "tweets_lw = api.user_timeline(\n",
    "    screen_name = \"lukas_warode\",\n",
    "    count = 1,\n",
    "    include_rts = False,\n",
    "    tweet_mode = \"extended\"\n",
    ")\n",
    "\n",
    "# print type of user_timeline method object\n",
    "type(tweets_lw)\n",
    "\n",
    "# function to convert tweepy object to a pandas dataframe\n",
    "def timeline_to_df(tweepy_timeline):\n",
    "    \"\"\"Take a tweety object input and return a pandas dataframe.\"\"\"\n",
    "    json_data = [r._json for r in tweepy_timeline]\n",
    "    df = pd.json_normalize(json_data)\n",
    "    return df\n",
    "\n",
    "# apply function \n",
    "tweets_lw_df = timeline_to_df(tweets_lw)\n",
    "\n",
    "# print full text column of tweet dataframe\n",
    "pd.options.display.max_colwidth = int(tweets_lw_df[\"full_text\"].str.len())\n",
    "print(tweets_lw_df[\"full_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use csv file from WZB project to extract list of German MPs' Twitter accounts\n",
    "## (Project author: Markus Konrad)\n",
    "\n",
    "If we want to match every MP's tweets with their respective party programmes, we need their twitter handles. Luckily, the Markus Konrad from WZB has done a quite similar project, and provides a file that contains all twitter handles from German MPs. In the next chunk, we read in this file and creating a dataframe that only contains the MP's handle and his/her party affiliation. NAs are dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv as dataframe from GitHub repository\n",
    "wzb_df = pd.read_csv(\"https://raw.githubusercontent.com/WZBSocialScienceCenter/mdb-twitter-network/master/data/deputies_twitter_20190702.csv\")\n",
    "\n",
    "# create subset with the 2 relevant columns and drop NAs\n",
    "twitter_df = wzb_df[[\"twitter_name\", \"party\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling approaches\n",
    "## a) Get random MP Twitter handles\n",
    "\n",
    "To check whether the previous steps have worked, the following chunk creates a function (`random_sample_handle`) that returns a certain number of random twotter handles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    smuellermdb\n",
      "   christophfdp\n",
      " nkleinwaechter\n",
      "      c_lindner\n",
      "       miro_spd\n"
     ]
    }
   ],
   "source": [
    "# Function to extract random MPs' Twitter handles\n",
    "def random_sample_handle(df, n):\n",
    "    \"\"\"\n",
    "    Take a twitter handle dataframe and a number and return a desired number of random handles.\n",
    "\n",
    "        Parameters:\n",
    "                df (str): A dataframe containing twitter handles\n",
    "                n (int): An integer \n",
    "        \n",
    "        Returns: \n",
    "                A specified number of random twitter handles\n",
    "    \"\"\"\n",
    "    sample = df[[\"twitter_name\"]].sample(n = n)\n",
    "    name_string = sample.to_string(index = False, header = False)\n",
    "    return name_string\n",
    "\n",
    "# apply function\n",
    "print(\n",
    "    random_sample_handle(\n",
    "        df = twitter_df,\n",
    "        n = 5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Extract Twitter handles by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kirstenkappert', 'konstantinnotz', 'markuskurthmdb', 'babetteschefin', 'sven_kindler', 'agnieszka_mdb', 'goeringeckardt', 'markustressel', 'beatewaro', 'julia_verlinden', 'jtrittin', 'k_sa', 'ulle_schauws', 'schickgerhard', 'manuelsarrazin', 'tabearoessner', 'crueffer', 'lisapaus', 'fostendorff', 'cem_oezdemir', 'nouripour', 'gruenebeate', 'irenemihalic', 'tobiaslindner', 'steffilemke', 'monikalazar', 'renatekuenast', 'chriskuehn_mdb', 'stephankuehn', 'oliver_krischer', 'mariaklschmeink', 'uwekekeritz', 'djanecek', 'brihasselmann', 'hajdukbundestag', 'kaigehring', 'matthiasgastel', 'katjadoerner', 'katdro', 'ebner_sha', 'ekindeligoez', 'fbrantner', 'kerstinandreae', 'abaerbock', 'w_sk', 'lieblingxhain', 'stefangelbhaar', 'danywagner_da', 'badulrichmartha', 'gruenclaudia', 'derdanyal', 'margaretebause', 'filizgreen', 'owvonholtz', 'svenlehmann', 'annachristmann']\n"
     ]
    }
   ],
   "source": [
    "# follower count function\n",
    "def follower_count_fun(twitter_handle):\n",
    "    try: \n",
    "        user = api.get_user(screen_name = twitter_handle)\n",
    "        count = user.followers_count\n",
    "        return count\n",
    "    except tweepy.TweepyException:\n",
    "        pass\n",
    "\n",
    "# for demonstration and simplification purposes we create a subset with Green MPs\n",
    "twitter_df_greens = twitter_df[twitter_df[\"party\"] == \"DIE GRÃœNEN\"]\n",
    "\n",
    "# store Twitter handles as list from data frame (column) with a function\n",
    "def col_to_tidy_list(df, col):\n",
    "    col_string = df[[col]].to_string(index = False, header = False)\n",
    "    tidy_string = col_string.replace(\" \", \"\")\n",
    "    tidy_list = tidy_string.split(\"\\n\")\n",
    "    return tidy_list\n",
    "\n",
    "# test and print results\n",
    "twitter_handles_list = col_to_tidy_list(\n",
    "    twitter_df_greens,\n",
    "    \"twitter_name\"\n",
    ")\n",
    "\n",
    "print(twitter_handles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function in a for loop and store follower count in list\n",
    "follower_count_list = []\n",
    "\n",
    "for twitter_name in twitter_handles_list:\n",
    "    follower_count_list.append(\n",
    "        follower_count_fun(twitter_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6194, 84955, 3963, None, 19422, 13577, 200537, 2012, None, 9569, 115093, 7415, 7682, 11899, 6524, 9208, 3429, 10953, None, 279590, 27582, 5744, 8857, 8897, 17437, 6331, 76514, 4450, 7485, 19540, 7651, 3351, 13616, 35254, 2390, 11903, 7413, 17858, 8398, 5337, 9375, 12738, 8865, 410042, 7506, 12863, 7740, 1707, 5589, 3047, 16986, 7330, 5547, 1740, 21858, 5051]\n"
     ]
    }
   ],
   "source": [
    "# print results \n",
    "print(follower_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        twitter_name       party  follower_count\n",
      "34    kirstenkappert  DIE GRÃœNEN          6194.0\n",
      "47    konstantinnotz  DIE GRÃœNEN         84955.0\n",
      "67    markuskurthmdb  DIE GRÃœNEN          3963.0\n",
      "68    babetteschefin  DIE GRÃœNEN             NaN\n",
      "71      sven_kindler  DIE GRÃœNEN         19422.0\n",
      "84     agnieszka_mdb  DIE GRÃœNEN         13577.0\n",
      "92    goeringeckardt  DIE GRÃœNEN        200537.0\n",
      "98     markustressel  DIE GRÃœNEN          2012.0\n",
      "122        beatewaro  DIE GRÃœNEN             NaN\n",
      "129  julia_verlinden  DIE GRÃœNEN          9569.0\n",
      "135         jtrittin  DIE GRÃœNEN        115093.0\n",
      "166             k_sa  DIE GRÃœNEN          7415.0\n",
      "176     ulle_schauws  DIE GRÃœNEN          7682.0\n",
      "179    schickgerhard  DIE GRÃœNEN         11899.0\n",
      "185   manuelsarrazin  DIE GRÃœNEN          6524.0\n",
      "189    tabearoessner  DIE GRÃœNEN          9208.0\n",
      "194         crueffer  DIE GRÃœNEN          3429.0\n",
      "221         lisapaus  DIE GRÃœNEN         10953.0\n",
      "226      fostendorff  DIE GRÃœNEN             NaN\n",
      "228     cem_oezdemir  DIE GRÃœNEN        279590.0\n",
      "229        nouripour  DIE GRÃœNEN         27582.0\n",
      "242      gruenebeate  DIE GRÃœNEN          5744.0\n",
      "251     irenemihalic  DIE GRÃœNEN          8857.0\n",
      "270    tobiaslindner  DIE GRÃœNEN          8897.0\n",
      "276      steffilemke  DIE GRÃœNEN         17437.0\n",
      "279      monikalazar  DIE GRÃœNEN          6331.0\n",
      "288    renatekuenast  DIE GRÃœNEN         76514.0\n",
      "290   chriskuehn_mdb  DIE GRÃœNEN          4450.0\n",
      "291     stephankuehn  DIE GRÃœNEN          7485.0\n",
      "296  oliver_krischer  DIE GRÃœNEN         19540.0\n",
      "304  mariaklschmeink  DIE GRÃœNEN          7651.0\n",
      "317      uwekekeritz  DIE GRÃœNEN          3351.0\n",
      "326         djanecek  DIE GRÃœNEN         13616.0\n",
      "352    brihasselmann  DIE GRÃœNEN         35254.0\n",
      "357  hajdukbundestag  DIE GRÃœNEN          2390.0\n",
      "375       kaigehring  DIE GRÃœNEN         11903.0\n",
      "380   matthiasgastel  DIE GRÃœNEN          7413.0\n",
      "397     katjadoerner  DIE GRÃœNEN         17858.0\n",
      "399           katdro  DIE GRÃœNEN          8398.0\n",
      "401        ebner_sha  DIE GRÃœNEN          5337.0\n",
      "402     ekindeligoez  DIE GRÃœNEN          9375.0\n",
      "416        fbrantner  DIE GRÃœNEN         12738.0\n",
      "439   kerstinandreae  DIE GRÃœNEN          8865.0\n",
      "443        abaerbock  DIE GRÃœNEN        410042.0\n",
      "446             w_sk  DIE GRÃœNEN          7506.0\n",
      "466    lieblingxhain  DIE GRÃœNEN         12863.0\n",
      "468   stefangelbhaar  DIE GRÃœNEN          7740.0\n",
      "491    danywagner_da  DIE GRÃœNEN          1707.0\n",
      "499  badulrichmartha  DIE GRÃœNEN          5589.0\n",
      "506     gruenclaudia  DIE GRÃœNEN          3047.0\n",
      "507        derdanyal  DIE GRÃœNEN         16986.0\n",
      "540   margaretebause  DIE GRÃœNEN          7330.0\n",
      "553       filizgreen  DIE GRÃœNEN          5547.0\n",
      "554       owvonholtz  DIE GRÃœNEN          1740.0\n",
      "647      svenlehmann  DIE GRÃœNEN         21858.0\n",
      "649   annachristmann  DIE GRÃœNEN          5051.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/2zjv_gf504q12hx7wv13j4y80000gn/T/ipykernel_47272/1539880663.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twitter_df_greens[\"follower_count\"] = follower_count_list\n"
     ]
    }
   ],
   "source": [
    "# add follower count list to data fraeme as a numeric column\n",
    "twitter_df_greens[\"follower_count\"] = follower_count_list\n",
    "\n",
    "# print transformed data frame\n",
    "print(twitter_df_greens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abaerbock\n"
     ]
    }
   ],
   "source": [
    "# filter observation with highest follower count\n",
    "max_followers = twitter_df_greens[\"follower_count\"].max()\n",
    "\n",
    "twitter_df_greens[twitter_df_greens[\"follower_count\"] == max_followers]\n",
    "\n",
    "# get twitter name column with highest follower count as string\n",
    "most_followers_mp = twitter_df_greens[twitter_df_greens[\"follower_count\"] == max_followers][\"twitter_name\"].to_string(index = False, header = False)\n",
    "\n",
    "print(most_followers_mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet extraction\n",
    "## convert `user_timeline` of **Annalena Baerbock** to data frame\n",
    "\n",
    "For this project, we exemplarily look at the tweets of Annalena Baerbock (BÃ¼ndnis 90/Green Party). In the next chunk, the `user_timeline`-function is used again, selecting the MP with the most followers, extracting the 200 last tweets, excluding retweets and storing them into a new object. Subsequently, the new object is transformed into a dataframe and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tweets\n",
    "baerbock_tweets = api.user_timeline(\n",
    "    # MP with most followers (Greens) - Annalena Baerbock\n",
    "    screen_name = most_followers_mp,\n",
    "    # maximum number of tweets extractable\n",
    "    count = 200,\n",
    "    # do not include retweets\n",
    "    include_rts = False,\n",
    "    # scope of retrieved information\n",
    "    tweet_mode = \"extended\"\n",
    ")\n",
    "\n",
    "# apply function that converts timeline object to data frame\n",
    "baerbock_tweets_df = timeline_to_df(baerbock_tweets)\n",
    "\n",
    "# print data frame\n",
    "print(baerbock_tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save relevant columns as `.csv` file\n",
    "\n",
    "As last steps, some non-required columns are dropped and only relevant variables are stored in a new object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset of complete data frame\n",
    "baerbock_tweets_subset_df = baerbock_tweets_df[[\n",
    "    \"id\", \n",
    "    \"created_at\",\n",
    "    \"full_text\",\n",
    "    \"display_text_range\",\n",
    "    \"in_reply_to_user_id\",\n",
    "    \"in_reply_to_screen_name\",\n",
    "    \"is_quote_status\",\n",
    "    \"retweet_count\",\n",
    "    \"favorite_count\",\n",
    "    \"possibly_sensitive\"\n",
    "]]\n",
    "\n",
    "# print subsetted data frame\n",
    "print(baerbock_tweets_subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking whether file already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baerbock_tweets.csv did not exist before\n",
      "Tweets are saved in a csv file\n"
     ]
    }
   ],
   "source": [
    "# save data frame as csv in case it does not already exist\n",
    "if os.path.isfile(\"baerbock_tweets.csv\"):\n",
    "    print(\"baerbock_tweets.csv already exists\")\n",
    "else:\n",
    "    print(\"baerbock_tweets.csv did not exist before\\nTweets are saved in a csv file\")\n",
    "    baerbock_tweets_subset_df.to_csv(\"baerbock_tweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
